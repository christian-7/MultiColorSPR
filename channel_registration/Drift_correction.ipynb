{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import the software libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Outline of steps\n",
    "1. Search the parent directory for all localization files and a build a list of such files\n",
    "2. Define the drift correction processor\n",
    "3. Open a file from the list\n",
    "4. Perform the drift correction on the file\n",
    "  * If the correction was not good, go back to step 2\n",
    "4. Save the results\n",
    "5. Repeat from step 1\n",
    "\n",
    "Tutorial: https://github.com/kmdouglass/bstore/blob/master/examples/Fiducial-based%20Drift%20Correction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import bstore.processors as proc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Search the parent directory and make a list of localization files\n",
    "We will start by searching a parent directory and its subdirectories for all the localization files, i.e. those files that end in `locResults.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "parentDirectory   = Path('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/')\n",
    "localizationFiles = parentDirectory.glob('**/Sas6_A647_*Localizations.csv')\n",
    "locResultFiles    = sorted(localizationFiles)\n",
    "\n",
    "# How many files are there? \n",
    "print(len(locResultFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_10_1/Sas6_A647_10_1_MMStack_1_Localizations.csv'),\n",
      "        0),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_11_1/Sas6_A647_11_1_MMStack_1_Localizations.csv'),\n",
      "        1),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_12_1/Sas6_A647_12_1_MMStack_1_Localizations.csv'),\n",
      "        2),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_13_1/Sas6_A647_13_1_MMStack_1_Localizations.csv'),\n",
      "        3),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_14_1/Sas6_A647_14_1_MMStack_1_Localizations.csv'),\n",
      "        4),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_15_1/Sas6_A647_15_1_MMStack_1_Localizations.csv'),\n",
      "        5),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_16_1/Sas6_A647_16_1_MMStack_1_Localizations.csv'),\n",
      "        6),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_17_1/Sas6_A647_17_1_MMStack_1_Localizations.csv'),\n",
      "        7),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_18_1/Sas6_A647_18_1_MMStack_1_Localizations.csv'),\n",
      "        8),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_19_1/Sas6_A647_19_1_MMStack_1_Localizations.csv'),\n",
      "        9),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_1_1/Sas6_A647_1_1_MMStack_1_Localizations.csv'),\n",
      "        10),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_20_1/Sas6_A647_20_1_MMStack_1_Localizations.csv'),\n",
      "        11),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_21_1/Sas6_A647_21_1_MMStack_1_Localizations.csv'),\n",
      "        12),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_22_1/Sas6_A647_22_1_MMStack_1_Localizations.csv'),\n",
      "        13),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_23_1/Sas6_A647_23_1_MMStack_1_Localizations.csv'),\n",
      "        14),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_24_1/Sas6_A647_24_1_MMStack_1_Localizations.csv'),\n",
      "        15),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_2_1/Sas6_A647_2_1_MMStack_1_Localizations.csv'),\n",
      "        16),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_3_1/Sas6_A647_3_1_MMStack_1_Localizations.csv'),\n",
      "        17),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_4_1/Sas6_A647_4_1_MMStack_1_Localizations.csv'),\n",
      "        18),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_5_1/Sas6_A647_5_1_MMStack_1_Localizations.csv'),\n",
      "        19),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_6_1/Sas6_A647_6_1_MMStack_1_Localizations.csv'),\n",
      "        20),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_7_1/Sas6_A647_7_1_MMStack_1_Localizations.csv'),\n",
      "        21),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_8_1/Sas6_A647_8_1_MMStack_1_Localizations.csv'),\n",
      "        22),\n",
      "    (   WindowsPath('E:/to_analyze/2017-12-08_humanCent_Cep152_Sas6/locResults/Sas6_A647_9_1/Sas6_A647_9_1_MMStack_1_Localizations.csv'),\n",
      "        23)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(locResultFiles, range(len(locResultFiles)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define the drift correction processor\n",
    "This part is the same as in Tutorial 1. At the end of processing for each file, return to this code block and start running the blocks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\to_analyze\\2017-12-08_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_9_1\\Sas6_A647_9_1_MMStack_1_Localizations.csv\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# Set the input and output files\n",
    "# Up to and including are 26 finished\n",
    "currentFile = locResultFiles[23] # Increment this when done dedrifting a dataset\n",
    "outputFile  = currentFile.parent / Path(currentFile.stem + '_DC' + currentFile.suffix)\n",
    "\n",
    "# Create the FiducialDriftCorrect processor and set its properties.\n",
    "dc = proc.FiducialDriftCorrect(coordCols = ['x [nm]', 'y [nm]'])\n",
    "dc.driftComputer.smoothingWindowSize = 800\n",
    "dc.driftComputer.smoothingFilterSize = 200\n",
    "\n",
    "clean = proc.CleanUp()\n",
    "\n",
    "# Open a file and clean it up\n",
    "with open(str(currentFile), 'r') as file:\n",
    "    df = pd.read_csv(file, sep = ',')\n",
    "    \n",
    "# Clean up the data\n",
    "df = clean(df)\n",
    "\n",
    "print(str(currentFile))\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    }
   ],
   "source": [
    "corrdf = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# Skip this cell if you don't need to adjust the fits\n",
    "dc.interactiveSearch = False\n",
    "\n",
    "# Modify these if needed to adjust the fits\n",
    "dc.driftComputer.useTrajectories     = [0] # Set to [] if you want to use all fiducials\n",
    "dc.driftComputer.zeroFrame           = 1000# Set to 1000 by default\n",
    "dc.driftComputer.smoothingWindowSize = 1800  # Set to 800 by default\n",
    "dc.driftComputer.smoothingFilterSize = 300   # Set to 300 by default\n",
    "dc.driftComputer.maxRadius = 500\n",
    "\n",
    "# processed_df = dc(df)\n",
    "corrdf = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# df.describe()\n",
    "# processed_df.head()\n",
    "corrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run this only if no good fiducials are found.\n",
    "# plt.close('all')\n",
    "# dc.driftComputer.fiducialLocs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\to_analyze\\2017-12-08_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_9_1\\Sas6_A647_9_1_MMStack_1_Localizations_DC.csv\n",
      "E:\\to_analyze\\2017-12-08_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_9_1\\Sas6_A647_9_1_MMStack_1_Localizations_Avg.csv\n",
      "E:\\to_analyze\\2017-12-08_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_9_1\\Sas6_A647_9_1_MMStack_1_Localizations_Fid.csv\n"
     ]
    }
   ],
   "source": [
    "saveTrajectories = True\n",
    "# If no fiducials were found, append '_DCX' to the filename;\n",
    "# Otherwise, append '_DC'\n",
    "if dc.driftComputer.fiducialLocs is None:\n",
    "    with open(str(currentFile), 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "    corrdf = clean(df)\n",
    "    outputFile = currentFile.parent / Path(currentFile.stem + '_DCX' + currentFile.suffix)\n",
    "    saveTrajectories = False\n",
    "    \n",
    "print(str(outputFile))\n",
    "\n",
    "# Save the data\n",
    "with open(str(outputFile), 'w') as file:\n",
    "    corrdf.to_csv(file, index=False)\n",
    "    \n",
    "if saveTrajectories:\n",
    "    # Save the average trajectory\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_AverageFiducialTrajectory' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Avg' + currentFile.suffix)\n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "        dc.driftTrajectory.to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))\n",
    "    \n",
    "    # Save the individual trajectories\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_FiducialTrajectories' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Fid' + currentFile.suffix)\n",
    "    #with open(str(outputTrajectoryFile), 'w') as file:\n",
    "    #   dc.driftComputer.fiducialLocs.loc[(slice(None), dc.driftComputer.useTrajectories), :].to_csv(file, index = True)\n",
    "    #print(str(outputTrajectoryFile))\n",
    "    \n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "            if dc.driftComputer.useTrajectories: # Important because the.loc will return None if all trajectories are used \n",
    "                dc.driftComputer.fiducialLocs.loc[(slice(None),dc.driftComputer.useTrajectories), :].to_csv(file, index = True)\n",
    "            else:\n",
    "                dc.driftComputer.fiducialLocs.to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))\n",
    "    \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can cycle back up to the beginning and increase the index locResultFiles array by one and repeat the process in this notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bstore]",
   "language": "python",
   "name": "conda-env-bstore-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
